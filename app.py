import streamlit as st
import asyncio
import os
import re
import json
import requests
import time
import random
from typing import Dict
from functools import lru_cache


def extract_text_from_pdf(file):
    try:
        from PyPDF2 import PdfReader
        pdf_reader = PdfReader(file)
        text = ''.join(page.extract_text() for page in pdf_reader.pages)
        return text
    except Exception as e:
        st.error(f"Error reading PDF: {e}")
        return None

def convert_markdown_to_text(markdown_content):
    """Convert markdown formatting to plain text with basic formatting"""
    # Replace headers with uppercase text and add line breaks
    text = re.sub(r'# (.*)', r'\n\n\1\n' + '='*40 + '\n', markdown_content)
    text = re.sub(r'## (.*)', r'\n\n\1\n' + '-'*40 + '\n', text)
    text = re.sub(r'### (.*)', r'\n\n\1\n' + '-'*30 + '\n', text)
    
    # Replace bullet points
    text = re.sub(r'- (.*)', r'‚Ä¢ \1', text)
    
    # Replace bold text
    text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)
    text = re.sub(r'__(.*?)__', r'\1', text)
    
    # Replace italic text
    text = re.sub(r'\*(.*?)\*', r'\1', text)
    text = re.sub(r'_(.*?)_', r'\1', text)
    
    # Clean up extra whitespace
    text = re.sub(r'\n\s*\n\s*\n', '\n\n', text)
    
    # Add a separator line at the end
    text += "\n\n" + "="*60 + "\nGenerated by JDmatcher\n" + "="*60
    
    return text

class GroqAPI:
    def __init__(self, api_key):
        self.api_key = api_key
        self.api_url = "https://api.groq.com/openai/v1/chat/completions"
        self.model = "llama-3.3-70b-versatile"  # Using Llama 3 70B from Groq
        
    async def generate_response(self, prompt, system_message="You are a helpful assistant.", max_retries=5):
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": system_message},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0,  # Changed from 0.7 to 0 for deterministic results
            "seed": 42,        # Added fixed seed for consistency
            "max_tokens": 2048
        }
        
        for attempt in range(max_retries):
            try:
                response = requests.post(self.api_url, headers=headers, data=json.dumps(data))
                response.raise_for_status()
                # Success - return the result
                return response.json()["choices"][0]["message"]["content"]
                
            except requests.exceptions.HTTPError as e:
                if e.response.status_code == 429:  # Too Many Requests
                    # Calculate wait time with exponential backoff and jitter
                    wait_time = (2 ** attempt) + random.uniform(1, 3)
                    st.warning(f"Rate limit hit. Waiting {wait_time:.2f} seconds before retry {attempt+1}/{max_retries}...")
                    await asyncio.sleep(wait_time)  # Using asyncio.sleep instead of time.sleep
                    continue
                else:
                    st.error(f"API Error: {e}")
                    return f"Error: {str(e)}"
                    
            except Exception as e:
                st.error(f"API Error: {e}")
                return f"Error: {str(e)}"
        
        # If we've exhausted all retries
        return "Error: Maximum retry attempts reached. Please try again later."

async def process_resume_and_jd(api_key, resume_text, job_description):
    groq = GroqAPI(your_api_key)
    
    try:
        # Step 1: Parse resume
        st.info("Step 1/4: Analyzing your resume...")
        resume_system_message = """You are an expert resume parser. Extract key information from the resume including:
        - Technical skills and proficiencies
        - Work experience and duration
        - Education and qualifications
        - Projects and achievements
        - Certifications
        Provide the information in a structured format for easy analysis."""
        
        resume_result = await groq.generate_response(
            f"Parse this resume content and extract key information: {resume_text}",
            resume_system_message
        )
        
        # Add delay between requests to avoid rate limiting
        await asyncio.sleep(2)
        
        # Step 2: Parse job description
        st.info("Step 2/4: Analyzing the job description...")
        jd_system_message = """You are an expert job description parser. Extract key requirements from the job description including:
        - Required technical skills
        - Minimum experience needed
        - Educational requirements
        - Key responsibilities
        - Soft skills and other attributes
        Provide the information in a structured format for easy comparison."""
        
        jd_result = await groq.generate_response(
            f"Parse this job description and extract key requirements: {job_description}",
            jd_system_message
        )
        
        # Add delay between requests to avoid rate limiting
        await asyncio.sleep(2)
        
        # Step 3: Analyze match
        st.info("Step 3/4: Calculating match score and analyzing fit...")
        match_system_message = """You are an expert resume-job match analyzer. Compare the resume with job description requirements to determine:
        - Overall match score as a clear percentage (e.g., "75% match")
        - Key matching skills and experiences
        - Missing skills or qualifications
        - Assessment of chances of selection
        
        IMPORTANT: Always start your analysis with a clear statement of the overall match percentage in the format "Match Score: XX%" on its own line.
        Provide a detailed analysis with specific examples."""
        
        match_result = await groq.generate_response(
            f"""Compare the following resume with the job description requirements:
            Resume information: {resume_result}
            Job requirements: {jd_result}
            
            Provide a detailed match analysis including percentage match and specific matching/missing elements.
            Be consistent and deterministic in your match score calculation.""",
            match_system_message
        )
        
        # Add delay between requests to avoid rate limiting
        await asyncio.sleep(2)
        
        # Step 4: Generate improvement suggestions
        st.info("Step 4/4: Generating improvement recommendations...")
        improvement_system_message = """You are an expert career advisor. Based on the gaps identified, provide actionable recommendations:
        - Specific skills to acquire or highlight
        - Resume improvements and restructuring suggestions
        - How to better position existing experience
        - Suggestions for addressing missing requirements
        - Interview preparation tips specific to this role
        Provide practical, specific advice that can be implemented."""
        
        improvement_result = await groq.generate_response(
            f"""Based on the following analysis:
            Resume information: {resume_result}
            Job requirements: {jd_result}
            Match analysis: {match_result}
            
            Provide detailed recommendations for improving the match and preparing for the application/interview process.""",
            improvement_system_message
        )
        
        # Compile final report
        final_report = f"""# Resume-Job Description Match Analysis

## Match Summary
{match_result}

## Resume Overview
{resume_result}

## Job Requirements Overview
{jd_result}

## Improvement Recommendations
{improvement_result}

*Report generated by JDmatcher*
"""
        
        return {
            "resume_analysis": resume_result,
            "jd_analysis": jd_result,
            "match_analysis": match_result,
            "improvement_suggestions": improvement_result,
            "final_report": final_report
        }
    except Exception as e:
        st.error(f"An error occurred during workflow execution: {e}")
        return {
            "resume_analysis": "", 
            "jd_analysis": "",
            "match_analysis": "",
            "improvement_suggestions": "",
            "final_report": ""
        }

# Streamlit App
async def main():
    st.title("HireWise: Resume & Job Description Analyzer")
    st.subheader("Find your match score and improve your chances")

    # Initialize session state for caching
    if "analysis_results" not in st.session_state:
        st.session_state.analysis_results = {}

    st.sidebar.header("Upload Files and API Key")
    api_key = st.sidebar.text_input("Enter your Groq API key:", type="password")
    if not api_key:
        st.warning("Please provide a valid Groq API key üôèüèª")
        return 
    
    resume_file = st.sidebar.file_uploader("Upload Resume PDF", type="pdf", accept_multiple_files=False)
    
    st.sidebar.header("Job Description")
    job_description = st.sidebar.text_area("Paste Job Description Here:", height=300)

    # Add a note about rate limits
    st.sidebar.info("Note: This application makes multiple API calls to analyze your resume and job description. If you encounter rate limit errors, please wait a few minutes before trying again.")

    if st.sidebar.button("Analyze Match"):
        if not api_key:
            st.error("Please enter a valid Groq API key to proceed. üôèüèª")
            return
            
        if not resume_file or not job_description:
            st.error("Please upload your resume and provide a job description.")
            return

        # Extract text from resume PDF
        resume_text = extract_text_from_pdf(resume_file)
        
        if not resume_text:
            st.error("Failed to extract text from the uploaded resume.")
            return
        
        # Create a unique key for the session state based on inputs
        # Use hash for large inputs to avoid key size issues
        analysis_key = f"{hash(resume_text)}_{hash(job_description)}"
        
        # Check if we already have results for this input combination
        if analysis_key in st.session_state.analysis_results:
            results = st.session_state.analysis_results[analysis_key]
            st.success("Retrieved cached analysis!")
        else:
            # Show processing status
            with st.status("Processing your match...", expanded=True) as status:
                st.write("Extracting resume content...")
                
                st.write("Analyzing resume and job description...")
                # Process resume and job description
                results = await process_resume_and_jd(api_key, resume_text, job_description)
                # Store results in session state for future use
                st.session_state.analysis_results[analysis_key] = results
                
                status.update(label="Analysis complete!", state="complete")

        # Display results
        if results and results.get("final_report"):
            st.success("Match analysis complete!")
            
            # Create tabs for different sections
            tab1, tab2, tab3 = st.tabs(["Match Analysis", "Detailed Report", "Download"])
            
            with tab1:
                # Extract and display match percentage with improved regex
                match_text = results.get("match_analysis", "")
                
                # More robust regex pattern that looks for variations of match percentages
                match_percentage = re.search(r'Match Score: (\d{1,3})%|(\d{1,3})%\s*match|match\s*(?:score|percentage|rate)?\s*(?:of|:)?\s*(\d{1,3})%', 
                                            match_text, re.IGNORECASE)

                if match_percentage:
                    # Get the first group that matched or subsequent ones if earlier ones are None
                    percentage = int(match_percentage.group(1) or match_percentage.group(2) or match_percentage.group(3))
                else:
                    # If no percentage found, extract number near "match" word
                    number_near_match = re.search(r'match.*?(\d{1,3})|(\d{1,3}).*?match', match_text, re.IGNORECASE)
                    percentage = int(number_near_match.group(1) or number_near_match.group(2)) if number_near_match else 50
                
                st.subheader("Match Score")
                st.progress(percentage/100)
                st.write(f"{percentage}% Match with Job Requirements")
                
                # Display key sections
                st.subheader("Key Matching Points")
                st.write(results.get("match_analysis", "No match analysis available"))
                
                st.subheader("Areas for Improvement")
                st.write(results.get("improvement_suggestions", "No improvement suggestions available"))
            
            with tab2:
                st.markdown(results.get("final_report", "No report available"))
            
            with tab3:
                # Create files for download
                markdown_report = results.get("final_report", "No report available")
                
                # Create markdown file for download
                with open("jdmatch_report.md", "w", encoding="utf-8") as f:
                    f.write(markdown_report)
                
                # Create plain text file for download
                plain_text_report = convert_markdown_to_text(markdown_report)
                with open("jdmatch_report.txt", "w", encoding="utf-8") as f:
                    f.write(plain_text_report)
                
                # Add download buttons
                col1, col2 = st.columns(2)
                
                with col1:
                    with open("jdmatch_report.md", "r", encoding="utf-8") as file:
                        st.download_button(
                            label="Download as Markdown",
                            data=file,
                            file_name="jdmatch_report.md",
                            mime="text/markdown"
                        )
                
                with col2:
                    with open("jdmatch_report.txt", "r", encoding="utf-8") as file:
                        st.download_button(
                            label="Download as Text File",
                            data=file,
                            file_name="jdmatch_report.txt",
                            mime="text/plain"
                        )
        else:
            st.error("Failed to generate analysis. Please try again later.")

# Run Streamlit App
if __name__ == "__main__":
    asyncio.run(main())
